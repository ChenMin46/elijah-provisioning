#!/usr/bin/env python
#
# Cloudlet Infrastructure for Mobile Computing
#
#   Author: Kiryong Ha <krha@cmu.edu>
#
#   Copyright (C) 2011-2013 Carnegie Mellon University
#   Licensed under the Apache License, Version 2.0 (the "License");
#   you may not use this file except in compliance with the License.
#   You may obtain a copy of the License at
#
#       http://www.apache.org/licenses/LICENSE-2.0
#
#   Unless required by applicable law or agreed to in writing, software
#   distributed under the License is distributed on an "AS IS" BASIS,
#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#   See the License for the specific language governing permissions and
#   limitations under the License.
#

import os
import traceback
import sys
import time
import struct
import SocketServer
import socket
import multiprocessing
from optparse import OptionParser

if os.path.exists("../elijah") is True:
    sys.path.insert(0, "../")
from elijah.provisioning.synthesis import validate_congifuration
from elijah.provisioning.server import NetworkUtil
from elijah.provisioning.synthesis_protocol import Protocol as Protocol
from elijah.provisioning.handoff import HandoffDataRecv
from elijah.provisioning.stream_server import RecoverDeltaProc, StreamSynthesisError
from elijah.provisioning.configuration import Const as Cloudlet_Const
from elijah.provisioning.compression import DecompProc
from elijah.provisioning import log as logging

from pprint import pformat


LOG = logging.getLogger(__name__)
session_resources = dict()   # dict[session_id] = obj(SessionResource)

class StreamSynthesisHandler(SocketServer.StreamRequestHandler):
    synthesis_option = {
        Protocol.SYNTHESIS_OPTION_DISPLAY_VNC: False,
        Protocol.SYNTHESIS_OPTION_EARLY_START: False,
        Protocol.SYNTHESIS_OPTION_SHOW_STATISTICS: False
        }

    def ret_fail(self, message):
        LOG.error("%s" % str(message))
        message = NetworkUtil.encoding({
            Protocol.KEY_COMMAND: Protocol.MESSAGE_COMMAND_FAILED,
            Protocol.KEY_FAILED_REASON: message
            })
        message_size = struct.pack("!I", len(message))
        self.request.send(message_size)
        self.wfile.write(message)

    def ret_success(self, req_command, payload=None):
        send_message = {
            Protocol.KEY_COMMAND: Protocol.MESSAGE_COMMAND_SUCCESS,
            Protocol.KEY_REQUESTED_COMMAND: req_command,
            }
        if payload:
            send_message.update(payload)
        message = NetworkUtil.encoding(send_message)
        message_size = struct.pack("!I", len(message))
        self.request.send(message_size)
        self.wfile.write(message)
        self.wfile.flush()

    def send_synthesis_done(self):
        message = NetworkUtil.encoding({
            Protocol.KEY_COMMAND: Protocol.MESSAGE_COMMAND_SYNTHESIS_DONE,
            })
        LOG.info("SUCCESS to launch VM")
        try:
            message_size = struct.pack("!I", len(message))
            self.request.send(message_size)
            self.wfile.write(message)
        except socket.error as e:
            pass

    def _recv_all(self, recv_size, ack_size=1024*1024):
        prev_ack_sent_size = 0
        data = ''
        while len(data) < recv_size:
            tmp_data = self.request.recv(recv_size-len(data))
            if tmp_data is None:
                msg = "Cannot recv data at %s" % str(self)
                raise StreamSynthesisError(msg)
            if len(tmp_data) == 0:
                raise StreamSynthesisError("Recv 0 data at %s" % str(self))
            data += tmp_data

            # to send ack for every PERIODIC_ACK_BYTES bytes
            cur_recv_size = len(data)
            data_diff = cur_recv_size-prev_ack_sent_size
            if data_diff > ack_size or cur_recv_size >= recv_size:
                ack_data = struct.pack("!Q", data_diff)
                self.request.sendall(ack_data)
                prev_ack_sent_size = cur_recv_size
        return data

    def _check_validity(self, message):
        header_info = None
        requested_base = None

        synthesis_option = message.get(Protocol.KEY_SYNTHESIS_OPTION, None)
        base_hashvalue = message.get(Cloudlet_Const.META_BASE_VM_SHA256, None)

        # check base VM
        for each_basevm in self.server.basevm_list:
            if base_hashvalue == each_basevm['hash_value']:
                LOG.info(
                    "New client request %s VM" %
                    (each_basevm['diskpath']))
                requested_base = each_basevm['diskpath']
        return [synthesis_option, requested_base]

    def handle(self):
        '''Handle request from the client
        Each request follows this format:

        | header size | header | blob header size | blob header | blob data  |
        |  (4 bytes)  | (var)  | (4 bytes)        | (var bytes) | (var bytes)|
        '''
        # variable
        self.total_recved_size_cur = 0
        self.total_recved_size_prev = 0

        # get header
        data = self._recv_all(4)
        if data is None or len(data) != 4:
            raise StreamSynthesisError(
                "Failed to receive first byte of header")
        message_size = struct.unpack("!I", data)[0]
        msgpack_data = self._recv_all(message_size)
        metadata = NetworkUtil.decoding(msgpack_data)
        launch_disk_size = metadata[Cloudlet_Const.META_RESUME_VM_DISK_SIZE]
        launch_memory_size = metadata[Cloudlet_Const.META_RESUME_VM_MEMORY_SIZE]

        synthesis_option, base_diskpath = self._check_validity(metadata)
        if base_diskpath is None:
            raise StreamSynthesisError("No matching base VM")
        base_diskpath, base_mempath, base_diskmeta, base_memmeta =\
            self.server.handoff_data.base_vm_paths
        LOG.info("  - %s" % str(pformat(self.synthesis_option)))
        LOG.info("  - Base VM     : %s" % base_diskpath)

        # variables for FUSE
        launch_disk = self.server.handoff_data.launch_diskpath
        launch_mem = self.server.handoff_data.launch_memorypath
        memory_chunk_all = set()
        disk_chunk_all = set()

        # start pipelining processes
        network_out_queue = multiprocessing.Queue()
        decomp_queue = multiprocessing.Queue()
        fuse_info_queue = multiprocessing.Queue()
        decomp_proc = DecompProc(network_out_queue, decomp_queue, num_proc=4)
        decomp_proc.start()
        LOG.info("Start Decompression process")
        delta_proc = RecoverDeltaProc(base_diskpath, base_mempath,
                                      decomp_queue,
                                      launch_mem,
                                      launch_disk,
                                      Cloudlet_Const.CHUNK_SIZE,
                                      fuse_info_queue)
        delta_proc.start()
        LOG.info("Start Synthesis process")

        # get each blob
        recv_blob_counter = 0
        while True:
            data = self._recv_all(4)
            if data is None or len(data) != 4:
                msg = "Failed to receive first byte of header"
                raise StreamSynthesisError(msg)

            blob_header_size = struct.unpack("!I", data)[0]
            blob_header_raw = self._recv_all(blob_header_size)
            blob_header = NetworkUtil.decoding(blob_header_raw)
            blob_size = blob_header.get(Cloudlet_Const.META_OVERLAY_FILE_SIZE)
            if blob_size is None:
                raise StreamSynthesisError("Failed to receive blob")
            if blob_size == 0:
                LOG.debug("%f\tend of stream" % (time.time()))
                break
            blob_comp_type = blob_header.get(
                Cloudlet_Const.META_OVERLAY_FILE_COMPRESSION)
            blob_disk_chunk = blob_header.get(
                Cloudlet_Const.META_OVERLAY_FILE_DISK_CHUNKS)
            blob_memory_chunk = blob_header.get(
                Cloudlet_Const.META_OVERLAY_FILE_MEMORY_CHUNKS)

            # send ack right before getting the blob
            ack_data = struct.pack("!Q", 0x01)
            self.request.send(ack_data)
            compressed_blob = self._recv_all(blob_size, ack_size=200*1024)
            # send ack right after getting the blob
            ack_data = struct.pack("!Q", 0x02)
            self.request.send(ack_data)

            network_out_queue.put((blob_comp_type, compressed_blob))
            memory_chunk_set = set(
                ["%ld:1" % item for item in blob_memory_chunk])
            disk_chunk_set = set(["%ld:1" % item for item in blob_disk_chunk])
            memory_chunk_all.update(memory_chunk_set)
            disk_chunk_all.update(disk_chunk_set)
            LOG.debug("%f\treceive one blob" % (time.time()))
            recv_blob_counter += 1

        network_out_queue.put(Cloudlet_Const.QUEUE_SUCCESS_MESSAGE)
        delta_proc.join()
        LOG.debug("%f\tdeltaproc join" % (time.time()))

        # send end message
        actual_resume_time = time.time()
        ack_data = struct.pack("!Qd", 0x10, actual_resume_time)
        LOG.debug("send ack to client: %d" % len(ack_data))
        self.request.sendall(ack_data)
        LOG.info("finished")

        disk_overlay_map = ','.join(disk_chunk_all)
        memory_overlay_map = ','.join(memory_chunk_all)
        sys.stdout.write("openstack\t%s\t%s\t%s\t%s" % (
                         launch_disk_size, launch_memory_size,
                         disk_overlay_map, memory_overlay_map))

    def terminate(self):
        # force terminate when something wrong in handling request
        # do not wait for joinining
        if hasattr(self, 'delta_proc') and self.delta_proc is not None:
            self.delta_proc.finish()
            if self.delta_proc.is_alive():
                self.delta_proc.terminate()
            self.delta_proc = None


class StreamSynthesisConst(object):
    SERVER_PORT_NUMBER = 8022
    VERSION = 0.1


class StreamSynthesisServer(SocketServer.TCPServer):

    def __init__(self, handoff_datafile,
                 port_number=StreamSynthesisConst.SERVER_PORT_NUMBER,
                 timeout=120):
        self._handoff_datafile = handoff_datafile
        self.port_number = port_number
        self.timeout = timeout
        self.handoff_data = self._load_handoff_data(self._handoff_datafile)
        self.basevm_list = self.check_basevm(
            self.handoff_data.base_vm_paths,
            self.handoff_data.basevm_sha256_hash
        )
        server_address = ("0.0.0.0", self.port_number)
        self.allow_reuse_address = True
        try:
            SocketServer.TCPServer.__init__(
                self,
                server_address,
                StreamSynthesisHandler)
        except socket.error as e:
            LOG.error(str(e))
            LOG.error("Check IP/Port : %s\n" % (str(server_address)))
            sys.exit(1)
        self.socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        self.socket.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
        LOG.info("* Server configuration")
        LOG.info(" - Open TCP Server at %s" % (str(server_address)))
        LOG.info(" - Time out for waiting: %d" % self.timeout)
        LOG.info(" - Disable Nagle(No TCP delay)  : %s" %
                 str(self.socket.getsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY)))
        LOG.info("-"*50)

    def _load_handoff_data(self, filepath):
        handoff_data = HandoffDataRecv.from_file(filepath)
        if handoff_data is None:
            raise StreamSynthesisError(
                "Invalid handoff recv data at %s" % filepath)
        LOG.info("Load handoff data file at %s" % filepath)
        return handoff_data

    def handle_error(self, request, client_address):
        SocketServer.TCPServer.handle_error(self, request, client_address)
        LOG.error("handling error from client %s\n" % (str(client_address)))
        LOG.error(traceback.format_exc())

    def handle_timeout(self):
        LOG.error("timeout error\n")

    def terminate(self):
        # close all thread
        if self.socket != -1:
            self.socket.close()

        global session_resources
        for (session_id, resource) in session_resources.iteritems():
            try:
                resource.deallocate()
            except Exception as e:
                msg = "Failed to deallocate resources for Session : %s" % str(
                    session_id)
                LOG.warning(msg)

    def check_basevm(self, base_vm_paths, hash_value):
        ret_list = list()
        LOG.info("-"*50)
        LOG.info("* Base VM Configuration")
        # check file location
        (base_diskpath,
         base_mempath,
         base_diskmeta,
         base_memmeta) = base_vm_paths
        if not os.path.exists(base_diskpath):
            LOG.warning("base disk is not available at %s" % base_diskpath)
        if not os.path.exists(base_mempath):
            LOG.warning("base memory is not available at %s" % base_mempath)
        if not os.path.exists(base_diskmeta):
            LOG.warning("disk hashlist is not available at %s" % base_diskmeta)
        if not os.path.exists(base_memmeta):
            LOG.warning(
                "memory hashlist is not available at %s" %
                base_memmeta)
        basevm_item = {'hash_value': hash_value, 'diskpath': base_diskpath}
        ret_list.append(basevm_item)

        LOG.info("  %s (Disk %d MB, Memory %d MB)" %
                (base_diskpath, os.path.getsize(base_diskpath)/1024/1024,
                 os.path.getsize(base_mempath)/1024/1024))
        LOG.info("-"*50)
        return ret_list


def main(argv=sys.argv):
    if not validate_congifuration():
        sys.stderr.write("failed to validate configuration\n")
        sys.exit(1)

    parser = OptionParser(usage="usage: %prog ")
    parser.add_option("-p", "--port", action="store", dest="port_number",
                      default=StreamSynthesisConst.SERVER_PORT_NUMBER,
                      help="port number for handoff")
    parser.add_option("-d", "--datafile", action="store",
                      dest="handoff_datafile", default=None,
                      help="specify datafile for handoff destination")
    settings, args = parser.parse_args(argv)
    if settings.handoff_datafile is None:
        sys.stderr.write("Need to specify path to the handoff datafile\n")
        sys.exit(1)
    settings.handoff_datafile = os.path.abspath(settings.handoff_datafile)

    server = StreamSynthesisServer(
        settings.handoff_datafile,
        int(settings.port_number), timeout=120,
    )
    try:
        server.handle_request()
    except Exception as e:
        # sys.stderr.write(str(e))
        server.terminate()
        sys.exit(1)
    except KeyboardInterrupt as e:
        sys.stdout.write("Exit by user\n")
        server.terminate()
        sys.exit(1)
    else:
        server.terminate()
        sys.exit(0)


if __name__ == "__main__":
    main()
